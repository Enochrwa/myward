{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d5ddc2-61b8-4061-8078-2654b06490c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GlobalMaxPooling2D\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Build the feature extractor\n",
    "def build_model():\n",
    "    base_model = ResNet50(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "    base_model.trainable = False\n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        GlobalMaxPooling2D()\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "model = build_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcde1298-a92f-46ba-a40b-9e43e8b271bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "from sklearn.preprocessing import normalize\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def extract_feature(img_path, model) -> np.ndarray:\n",
    "    try:\n",
    "        img = Image.open(img_path).convert('RGB').resize((224, 224))\n",
    "        img_array = image.img_to_array(img)\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "        img_array = preprocess_input(img_array)\n",
    "\n",
    "        features = model.predict(img_array)\n",
    "        features = features.flatten()\n",
    "\n",
    "        normalized = normalize([features])[0]\n",
    "        return normalized\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to process {img_path}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a35017a-ae3b-425e-8418-d5390014e9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "model = build_model()\n",
    "IMG_DIR = \"wardrobe_images/wardrobe_images\"\n",
    "FEATURES_DIR = \"features\"\n",
    "os.makedirs(FEATURES_DIR, exist_ok=True)\n",
    "\n",
    "feature_map = {}\n",
    "\n",
    "for category in os.listdir(IMG_DIR):\n",
    "    category_path = os.path.join(IMG_DIR, category)\n",
    "    if not os.path.isdir(category_path):\n",
    "        continue\n",
    "\n",
    "    for img_name in tqdm(os.listdir(category_path), desc=category):\n",
    "        img_path = os.path.join(category_path, img_name)\n",
    "        features = extract_feature(img_path, model)\n",
    "\n",
    "        if features is not None:\n",
    "            feature_map[img_path] = features\n",
    "\n",
    "# Save all features\n",
    "with open(os.path.join(FEATURES_DIR, \"features.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(feature_map, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6e3b35-3681-46f4-be4e-a75ba4094108",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tags(filename: str):\n",
    "    name = os.path.basename(filename).lower()\n",
    "    parts = name.split(\"_\")\n",
    "    if len(parts) >= 4:\n",
    "        return {\n",
    "            \"color\": parts[1],\n",
    "            \"type\": parts[2],\n",
    "            \"occasion\": parts[3]\n",
    "        }\n",
    "    return {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8cafe5-e79a-4eaf-b942-18a919bfe645",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Load features\n",
    "with open(\"features/features.pkl\", \"rb\") as f:\n",
    "    features_dict = pickle.load(f)\n",
    "\n",
    "paths = list(features_dict.keys())\n",
    "features = np.array(list(features_dict.values()))\n",
    "\n",
    "# Build KNN model\n",
    "knn = NearestNeighbors(n_neighbors=5, metric='cosine')\n",
    "knn.fit(features)\n",
    "\n",
    "def recommend_similar(image_path, model):\n",
    "    feat = extract_feature(image_path, model)\n",
    "    distances, indices = knn.kneighbors([feat])\n",
    "    return [paths[i] for i in indices[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a561c18-7271-4004-ace2-2e3232be7d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_by_occasion(image_path, model, occasion, metadata):\n",
    "    filtered = [(p, f) for p, f in metadata.items() if parse_tags(p).get(\"occasion\") == occasion]\n",
    "    if not filtered:\n",
    "        return []\n",
    "    \n",
    "    paths, feats = zip(*filtered)\n",
    "    knn = NearestNeighbors(n_neighbors=5, metric='cosine').fit(feats)\n",
    "\n",
    "    feat = extract_feature(image_path, model)\n",
    "    distances, indices = knn.kneighbors([feat])\n",
    "    return [paths[i] for i in indices[0]]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
